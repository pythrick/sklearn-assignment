{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(classifier, X_test, y_test, target_names):\n",
    "    y_predicted = classifier.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_predicted,\n",
    "                                        target_names=target_names))\n",
    "    cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(pipeline, parameters, X_train, y_train):\n",
    "    gsc = GridSearchCV(\n",
    "        pipeline,\n",
    "        parameters,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gsc = gsc.fit(X_train, y_train)\n",
    "    print(\"Best score: \", gsc.best_score_)\n",
    "    print(\"Best parameters: \")\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, gsc.best_params_[param_name]))\n",
    "    return gsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 2000\n",
      "Target names: ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "movie_reviews_data_folder = r\"./data\"\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "print('Size:', len(dataset.data))\n",
    "print('Target names:', dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, \n",
    "    dataset.target, \n",
    "    test_size=0.25, \n",
    "    random_state=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escreva *pipeline de classificação de texto* para classificar reviews de filmes como positivos e negativos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encontre um bom conjunto de parâmetros utilizando `GridSearchCV`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0, 0.5, 1.0),\n",
    "              'clf__fit_prior': (True, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Avalie o classificador utilizando parte do conjunto de dados (previamente separado para testes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8306666666666664\n",
      "Best parameters: \n",
      "clf__alpha: 0.5\n",
      "clf__fit_prior: True\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.81      0.83       251\n",
      "         pos       0.82      0.86      0.84       249\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.83      0.83       500\n",
      "weighted avg       0.83      0.83      0.83       500\n",
      "\n",
      "[[204  47]\n",
      " [ 36 213]]\n"
     ]
    }
   ],
   "source": [
    "classifier = grid_search(pipeline, parameters, X_train, y_train)\n",
    "results = report(classifier, X_test, y_test, dataset.target_names)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escreva pipeline de classificação de texto para classificar reviews de filmes como positivos e negativos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encontre um bom conjunto de parâmetros utilizando `GridSearchCV`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__loss': (\"hinge\", \"squared_hinge\"),\n",
    "              'clf__dual': (True, False),\n",
    "              'clf__fit_intercept': (True, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Avalie o classificador utilizando parte do conjunto de dados (previamente separado para testes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/.local/pipx/venvs/jupyter/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8460000000000001\n",
      "Best parameters: \n",
      "clf__dual: True\n",
      "clf__fit_intercept: False\n",
      "clf__loss: 'hinge'\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.83      0.84       251\n",
      "         pos       0.84      0.86      0.85       249\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.84      0.84      0.84       500\n",
      "weighted avg       0.84      0.84      0.84       500\n",
      "\n",
      "[[209  42]\n",
      " [ 36 213]]\n"
     ]
    }
   ],
   "source": [
    "classifier = grid_search(pipeline, parameters, X_train, y_train)\n",
    "results = report(classifier, X_test, y_test, dataset.target_names)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optei por utilizar os algoritmos de classificação MultinomialNB e o LinearSVC, apesar de ter utilizado em ambos as features CountVectorizer e TfidTransformer, com parametros diferentes nas pipelines, o resultado foi bem próximo um do outro. Enquanto o MultinomialNB teve seu melhor resultado com 83% o LinearSVC teve um resultado de 84% acertos. \n",
    "\n",
    "Utilizei a função GridSearchCV para encontrar o melhor conjunto de parametros para cada uma das features. \n",
    "\n",
    "Para o MultinomialNB a melhor combinação foi a seguinte:\n",
    "- clf__alpha: 0.5\n",
    "- clf__fit_prior: True\n",
    "- tfidf__use_idf: True\n",
    "- vect__ngram_range: (1, 2)\n",
    "\n",
    "Para o LinerSVC a melhor combinação foi a seguinte:\n",
    "- clf__dual: True\n",
    "- clf__fit_intercept: False\n",
    "- clf__loss: 'hinge'\n",
    "- tfidf__use_idf: True\n",
    "- vect__ngram_range: (1, 1)\n",
    "\n",
    "No relatório de classificação é possível ver que eles tiveram o mesmo resultado para a precisão de negativos e recall de positivos. Porém na precisão de positivos e recall de negativos o algoritmos LinearSVC se sai melhor.\n",
    "\n",
    "Na matriz de confusão podemos ver que ambos algoritmos classificaram os verdadeiros positivos 213 das vezes, enquanto o LinearSVC se sai melhor na classificação de verdadeiros negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
